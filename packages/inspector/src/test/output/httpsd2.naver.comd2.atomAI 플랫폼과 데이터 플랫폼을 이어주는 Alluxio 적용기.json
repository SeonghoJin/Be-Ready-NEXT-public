{"company":{"imageUrl":"/companyImages/naver.ico","name":"네이버","rssUrl":"https://d2.naver.com/d2.atom","href":"https://d2.naver.com/d2.atom","basePath":"https://d2.naver.com"},"title":"AI 플랫폼과 데이터 플랫폼을 이어주는 Alluxio 적용기","createdAt":"2022-05-27T11:42:57Z","description":"고성능의 AI 모델을 개발하기 위해서는 좋은 알고리즘만큼이나 양질의 데이터가 중요합니다. 그렇기 때문에 대규모 데이터를 전처리하여 양질의 데이터로 만든 후 AI 플랫폼에서 이를 사용하는 것이 일반적입니다.\n\n네이버 검색에서는 어떻게 하고 있을까요? 네이버의 대규모 데이터는 데이터 저장소인 Cuve에 저장되어 있으며, Apache Hadoop 기반의 데이터 처리 플랫폼 C3에서 데이터를 처리합니다. 그리고 AI 학습 또는 서빙을 위해서는 Kubernetes 기반의 AI 플랫폼인 AiSuite를 사용합니다.\n\n즉, 네이버 검색에서 AI 서비스를 위한 데이터 흐름은 다음과 같습니다(AI&Data Platform 참고).\n\n\n데이터 저장 플랫폼 Cuve에서 대규모의 원본 데이터 관리  \n데이터 처리 플랫폼 C3에서 데이터 저장 플랫폼 Cuve의 데이터를 가공하여 HDFS에 저장  \nAiSuite는 데이터 처리 플랫폼 C3의 HDFS에 저장된 데이터를 사용\n\n\n결국 원활한 AI 파이프라인 개발을 위해서는 AiSuite에서 데이터 처리 플랫폼 C3의 HDFS에 빠르고 쉽게 접근할 수 있어야 합니다.\n\n\n\n본 문서에서는 Kubernetes 기반의 AI 플랫폼인 AiSuite에서 HDFS에 쉽고 빠르게 접근하기 위해 고민했던 내용을 공유합니다.\n\n요구 사항\n\n사용 편이성\n\nKubernetes에서 HDFS에 접근하기 위해서는 어떻게 해야 할까?\n\n단순하게 생각해보면 HDFS를 사용하는 방법은 어렵지 않다. Apache Hadoop 패키지, 클러스터 설정 파일을 배포하고 Kerberos 인증을 제공한 후 HDFS CLI, REST, Java API를 사용하여 접근할 수 있다.\n\n하지만 이는 Kubernetes에서 HDFS에 접근하려는 모든 컨테이너에 Apache Hadoop 패키지, 설정, 인증이 필요하다는 의미이다. 사용자가 매번 HDFS에 접근이 가능한 이미지를 직접 빌드하고 인증 방법을 마련해야 한다면 굉장히 번거로울 것이다. 그뿐만 아니라, HDFS CLI, REST, Java API 등을 이용한 HDFS 접근을 위한 코드 작성도 필요하다.\n\n따라서 HDFS를 사용하더라도 추가적인 개발이 없도록 지원해야 한다.\n\n이식성\n\nAiSuite는 Kubernetes 기반에서 Kubeflow, Knative, KServe 등의 다양한 소프트웨어를 활용하여 MLOps 환경을 제공한다.\n\n이렇게 다양한 소프트웨어에서 스토리지가 필요하다면 어떻게 지원할까? Kubernetes에서는 PersistentVolume을 마운트하여 사용하는 것이 일반적인 스토리지 사용 방법이다. HDFS를 스토리지로 사용하는 경우에도 이러한 방식을 지원한다면 Kubernetes에서 실행되는 어떠한 소프트웨어에서도 자연스럽게 HDFS를 사용할 수 있다.\n\n성능\n\nAiSuite의 GPU 노드는 여러 IDC에 걸쳐 분산되어 있으며, HDFS가 구축된 IDC와 다를 수 있다. 이러한 환경에서 항상 HDFS에 접근하는 경우 다량의 IDC 간 트래픽이 수시로 발생하며 데이터 전송이 지연된다.\n\nGPU를 활용하는 AI 작업에서 데이터 전송 지연은 단순히 오래 걸리는 것 이상의 비용이 발생한다. 일반적으로 GPU가 할당된 후 학습 또는 서빙에 필요한 데이터를 원격의 저장소로부터 가져오기 때문에, 데이터 전송이 지연된다면 그만큼 고비용의 GPU 자원을 낭비하는 것과 같다.\n\n따라서 한 번 읽은 데이터는 캐싱하여 효율적으로 접근하는 방법이 필요하다.\n\nKubernetes 저장소로 HDFS 활용\n\n클라우드 환경에서는 AWS S3, GCS와 같은 스토리지 서비스를 사용하여 안정적인 데이터 보관이 가능하다. 하지만 on-premise Kubernetes에서 영구적인 데이터 저장 스토리지는 어떻게 마련할 수 있을까?\n\n간단한 방법으로 nfs, local, hostpath 등을 생각할 수 있으나 고가용성 부족, 스케줄링 제한, 보안 취약 등의 문제가 있다. 안정적인 지원을 위해서는 Ceph, gluster 등의 분산 스토리지를 직접 구축하고 운영해야 하는 부담이 생긴다.\n\n이미 네이버에서는 데이터 처리 플랫폼 C3에서 지원하는 HDFS를 데이터 저장 용도로 사용하고 있다. 따라서 AiSuite에서 생성한 데이터를 HDFS에 저장한다면 별도의 분산 스토리지 도입 없이 안정적인 데이터 보관이 가능하다.\n\nAlluxio\n\nAlluxio란\n\n이러한 요구 사항을 위해 Alluxio를 검토했다.\n\nAlluxio는 Data Orchestration layer로 소개되며 다음과 같은 이점이 있다.\n\n\n물리적으로 멀리 떨어져 있거나 느린 저장매체에 저장된 데이터를 캐싱\nHDFS, AWS S3, GCS, Ceph 등의 다양한 스토리지에 원하는 인터페이스로 접근\n\n\nAlluxio는 주로 여러 클라우드 또는 내부 저장소의 데이터에 쉽고 빠르게 접근하기 위해 활용되고 있다.\n\n\nAWS S3에 저장된 데이터를 Spark, Presto 등에서 빠르게 처리\non-premise HDFS 데이터를 AWS, GCP 등의 클라우드에서 빠르게 접근\nAWS S3, GCS, Azure 등 여러 클라우드에 저장된 데이터 접근 방식을 일원화\n\n\n\n\nAlluxio의 아키텍처\n\nAlluxio는 파일의 메타 데이터를 관리하는 master와 데이터 블럭을 저장하는 다수의 worker로 구성되며, 이러한 구조는 HDFS와 유사하다. 하지만 데이터를 안정적으로 보관하는 용도라기보다는 캐싱과 다양한 인터페이스를 지원하여 데이터를 빠르고 쉽게 사용하는 데 목적이 있다.\n\n\n\n출처: https://docs.alluxio.io/os/user/stable/en/overview/Architecture.html\n\n데이터를 처음으로 읽는 경우에는 원본 저장소로부터 데이터를 가져오지만 이후에는 로컬 또는 다른 worker에 캐싱된 데이터를 가져오는 것이 기본적인 동작이다.\n\n\nlocal cache hit: 동일 노드의 worker에 캐싱된 데이터를 읽음(로컬 파일 시스템 속도)\nremote cache hit: 다른 노드의 worker에 캐싱된 데이터를 읽음(private network 속도)\ncache miss: 캐싱되어 있지 않은 경우 원본 저장소에서 데이터를 읽고 캐싱(원본 저장소 속도)\n\n\n\n\n출처: https://docs.alluxio.io/os/user/stable/en/overview/Architecture.html\n\n데이터를 쓰는 경우에도 용도에 따라 다양한 방식을 지원한다.\n\n\nMUST_CACHE: 임시 캐싱만 수행. 빠르지만 데이터 유실 가능\nCACHE_THROUGH: 원본 저장소로 저장한 이후 종료. 느리지만 안전한 데이터 보관\nASYNC_THROUGH: 캐싱 후 종료. 이후 비동기적으로 원본 저장소에 저장. 빠르지만 데이터 유실 가능\n\n\n\n\n출처: https://docs.alluxio.io/os/user/stable/en/overview/Architecture.html\n\n본 문서에서는 Alluxio 설치, 튜닝 방법 등의 상세한 내용을 다루지는 않는다. 자세한 내용은 alluxio.io을 참고하시기 바란다. 이후로는 AiSuite에 Alluxio를 도입하기 위해 고려했던 내용을 위주로 설명한다.\n\nKubernetes 저장소로 HDFS 활용\n\nAlluxio FUSE\n\nAlluxio는 데이터 접근을 위한 다양한 인터페이스를 지원하며, Linux FUSE 기반의 Alluxio FUSE를 사용하여 POSIX API를 지원한다. 즉, 별도의 Alluxio 라이브러리가 필요하지 않고 일반적인 파일 시스템과 동일하게 사용할 수 있다. 예를 들어, HDFS 접근 시에도 ls, mkdir, cat 등을 그대로 사용할 수 있으며, 데이터를 읽어오는 기존에 작성된 코드를 변경없이 사용할 수 있다. 이는 위의 요구 사항 중 사용 편이성, 이식성을 위해 필요하다.\n\n\n\n출처: https://docs.alluxio.io/os/user/edge/en/api/POSIX-API.html#choose-posix-api-implementation\n\n그렇다면 Alluxio FUSE를 Kubernetes에서 어떻게 지원해야 할까? 쉽게 떠오르는 것은 Kubernetes 모든 노드의 특정 경로에 Alluxio FUSE를 마운트하고 hostPath로 사용하는 것이다.\n\n하지만 AiSuite와 같이 여러 사용자가 함께 사용하는 다중 테넌트(multi-tenant) 환경에서는 다음과 같은 문제가 있다.\n\n\n하나의 FUSE 마운팅 포인트를 여러 사용자가 공유함으로서 성능 영향\n사용자별 HDFS 권한에 따른 접근 제어가 어려움\n\n\n그뿐만 아니라, hostPath는 보안 이슈를 일으킬 수 있어 부득이한 경우를 제외하면 사용하지 않도록 권고하고 있다. Kubernetes에서 스토리지는 PersistentVolume으로 사용하는 것이 일반적인 방식이다. Alluxio 파일 시스템에 접근하는 경우에도 이러한 방식을 지원하는 것이 필요하다.\n\n컨테이너 스토리지 인터페이스\n\nKubernetes에서 PersistentVolume은 어떻게 지원할 수 있을까?\n\n컨테이너 스토리지 인터페이스(이하 CSI)는 컨테이너 오케스트레이션 시스템(Kubernetes, swarm, mesos 등)에서 다양한 스토리지를 지원하기 위한 인터페이스를 정의한다. 이전에는 스토리지 지원을 위한 플러그인들이 컨테이너 오케스트레이션 시스템에 종속적이었다. 예를 들어, 스토리지 플러그인을 추가하거나 업데이트하려면 Kubernetes와 같이 컴파일 또는 배포되어야 했다. 하지만 CSI가 소개되면서 플러그인을 독립적으로 배포하고 관리할 수 있게 되었다. 즉, 스토리지 벤더측에서 CSI를 준수하는 스토리지 플러그인을 제공한다면 Kubernetes에 이를 배포하는 것으로 스토리지를 사용할 수 있다.\n\n\n\n출처: https://kubernetes.io/blog/2018/08/02/dynamically-expand-volume-with-csi-and-kubernetes/\n\nCSI에 대한 자세한 내용은 CSI spec을 참고하기 바란다.\n\nAlluxio CSI\n\n따라서 Alluxio 파일 시스템에 대한 CSI 스토리지 플러그인을 개발해야 한다는 걸 알 수 있다.\n\nAiSuite를 위한 플러그인은 아래와 같이 동작하도록 구현했다. 아래는 구현된 부분을 강조한 대략적인 흐름이다.\n\n\n\n(1) 사용자는 PVC(PersistentVolumeClaim), Pod 요청. 원하는 HDFS 경로를 PVC의 hdfs/namespace, hdfs/path로 명시\n\n(2.1) csi-provisioner에 의해 CreateVolume이 플러그인으로 요청\n\n(2.2) 플러그인은 PVC에 설정된 HDFS 경로를 Alluxio 파일 시스템과 마운트\n\n(3.1) Pod이 스케줄링되면, csi-attacher에 의해 ControllerPublishVolume이 플러그인으로 요청\n\n(3.2) 플러그인은 사용자가 PVC에 설정된 HDFS 경로에 대한 권한이 있는지 Ranger에 요청하여 확인\n\n(3.3) 플러그인은 HDFS와 Alluxio 파일 시스템과의 메타데이터 동기화 요청\n\n(4.1) 스케줄링된 노드의 kubelet은 NodePublishVolume을 플러그인으로 요청\n\n(4.2) 플러그인은 Alluxio 파일 시스템을 Pod 하위 경로에 Alluxio FUSE를 마운트하여 제공\n\nAlluxio에서도 Alluxio/alluxio-csi를 지원하지만, 다중 테넌트 환경에서 HDFS와 연동하기 위한 목적인 AiSuite에서는 다음과 같은 개발이 추가로 필요했다.\n\n\n사용자가 필요한 HDFS 경로를 직접 PVC에 설정하여 요청(1)\n여러 사용자가 공유하는 Alluxio 파일 시스템의 효율적인 사용을 위해 필요한 HDFS 경로만 캐싱(2.2)\nHDFS 접근 권한을 관리하는 Ranger와 연동하여 사용자 접근 제한(3.2)\nHDFS 네임노드로의 부하를 줄이기 위해 Pod 사용 시점에 한 번만 매뉴얼한 동기화 요청(3.3)(Alluxio와 HDFS 간 동기화 참고)\n\n\n결국 Alluxio CSI를 개발하여 HDFS를 일반적인 Kubernetes 스토리지와 동일한 방식으로 사용할 수 있게 되었다.\n\nAlluxio의 읽기 성능\n\nAlluxio 캐싱으로 인한 효과를 살펴보기 위해 여러 가지 조건에서 6.4GB 파일을 읽어 보았다. 테스트는 Alluxio 2.4.1에서 short-circuit read와 같은 성능 최적화 없이 진행되었다. 측정된 시간은 IDC 위치, 저장매체, Alluxio 버전 또는 설정 등에 영향을 받기 때문에 절대적인 것은 아니다.\n\n위에서 살펴본 대로 우리는 Alluxio FUSE가 필요하므로, Alluxio FUSE를 사용한 테스트를 진행했다.\n\n\n\n\nAlluxio FUSE로 캐싱되지 않은 파일을 읽는 경우(3), HDFS Client를 사용해 읽는 것(2)보다도 15% 가량 느려졌다. FUSE는 여러번 kernel-user 간 컨텍스트 스위칭이 발생하는데 이에 대한 오버헤드이다.\nAlluxio FUSE로 동일 노드에 캐싱된 파일을 읽는 경우(4), 캐싱되지 않는 파일을 읽는 경우(3)에 비해 5배 빠르게 읽어온다(short-circuit read 설정으로 더 빠른 속도도 기대할 수 있다).\nAlluxio FUSE로 다른 노드에 캐싱된 파일을 읽는 경우(5)에도 동일 노드에 캐싱된 파일을 읽는 경우(4)에 근사한 시간이 소요되었다.\n\n\nAlluxio 측에서도 Fuse 성능 개선에 노력하고 있으며, Alluxio 2.5.0부터는 성능을 개선한 JNI-Fuse를 사용할 수 있다.\n\n파일을 쓰는 경우에 대한 성능은 평가하지 않았다. AiSuite에서 Alluxio 파일을 쓰는 것은 HDFS를 안정적인 스토리지로 사용하기 위함이며, 따라서 HDFS로의 저장을 보장하는 CACHETHROUGH 방식을 사용한다. 따라서, 일반적인 HDFS Client를 사용하는 것과 비슷한 시간이 소요된다. 만약 데이터 유실을 감수할 수 있는 임시 데이터 보관이 목적이라면 MUSTCACHE를 사용하여 빠른 쓰기 성능을 기대할 수 있다.\n\nLocality\n\nAiSuite에 포함된 노드는 여러 IDC에 걸쳐 분산되어 있다. 데이터에 접근할 때 가능하면 IDC를 벗어나지 않고 근거리에서 데이터를 가져올 수 있어야 한다. 다른 IDC의 노드에서 데이터를 가져오는 경우, 느릴 뿐만 아니라 IDC 간 네트워크 트래픽 비용이 발생한다.\n\nAlluxio에서는 client, master, worker에 대해 locality를 부여하는 방법을 제공한다. Alluxio 파일 시스템에 접근하려는 client의 locality에 따라 어떤 worker로부터 캐싱된 데이터를 가져올지 결정할 수 있다.\n\nAiSuite에서는 node, zone, idc 순서로 locality를 고려하여 캐싱 데이터에 접근하도록 설정한다. zone은 용도에 따른 노드들의 그룹으로, 물리적으로 가까이 위치한다. 각 노드에는 node, zone, idc에 대한 Kubernetes node-label을 설정해두고, client, master, worker가 구동될 때 다음과 같은 alluxio.locality 설정이 반영되도록 했다.\n\n\nalluxio.locality.order=node,zone,idc\nalluxio.locality.node={노드의 호스트명}\nalluxio.locality.zone={노드가 소속된 zone명}\nalluxio.locality.idc={노드가 위치한 idc명}\n\n\n다음은 node=node1, zone=web, idc=seoul인 client에서 캐싱 데이터에 접근하는 예이다.\n\n\n\n\n같은 노드 node1에 캐싱된 데이터  \n같은 zone인 web에 캐싱된 데이터  \n같은 idc인 seoul에 캐싱된 데이터  \n그 외 다른 idc에 캐싱된 데이터\n\n\n만약 IDC 간 전송이 너무 느리거나 많은 비용이 발생한다면 어떻게 해야 할까? 다른 IDC에 캐싱된 데이터를 가져오는 것(위의 4번)보다, 같은 IDC의 HDFS에서 데이터를 가져오는 게 유리할 수 있다. 이 경우 alluxio.locality.idc.strict=true를 설정할 수 있다. 다른 IDC로의 요청 대신 HDFS로부터 데이터를 가져온다.\n\nAlluxio와 HDFS 간 동기화\n\nAlluxio는 HDFS 메타데이터(파일, 디렉터리 등의 정보)를 캐싱하여 빠르고 효율적으로 데이터를 사용하게 한다. 그뿐만 아니라, 메타데이터를 캐싱하여 HDFS 네임노드로의 불필요한 요청을 줄이는 이점도 있다.\n\n하지만 캐싱은 원본 저장소와의 불일치를 유발하기도 한다. Alluxio를 이용하여 파일, 디렉터리를 생성하는 경우에는 Alluxio 파일 시스템에 반영된다. 하지만 외부로부터 가해지는 HDFS 변경을 알 수는 없다. 예를 들어, Alluxio에서 /data/20220401을 캐싱하고 있는데 만약 Hive를 이용해 HDFS에 /data/20220402가 생성된다면 Alluxio는 알 수 없다.\n\n\n\n출처: https://www.alluxio.io/blog/two-ways-to-keep-files-in-sync-between-alluxio-and-hdfs\n\n이를 위해 Alluxio에서는 얼마나 자주 HDFS와 메타데이터 동기화를 해야 하는지 client 측에 설정할 수 있다.\n\n\nalluxio.user.file.metadata.sync.interval=-1는 한 번 캐싱한 이후로는 동기화하지 않는다. HDFS 네임노드로의 부담은 줄어들지만 동기화 문제가 발생할 수 있다.\nalluxio.user.file.metadata.sync.interval=0은 파일 접근이 있을 때마다 HDFS 메타데이터를 동기화한다. 동기화 문제는 없지만, HDFS 네임노드로 항상 listStatus 요청이 발생하여 네임노드에 부담을 준다.\nalluxio.user.file.metadata.sync.interval=1m는 1분마다 HDFS 메타데이터와 동기화한다. 1분마다 주기적으로 listStatus 요청이 발생한다.\n\n\n우리가 사용하는 C3S HDFS는 수많은 사용자가 있다. 따라서 무엇보다도 네임노드 부담을 줄이기 위한 방안이 필요하므로 alluxio.user.file.metadata.sync.interval=-1를 기본으로 사용한다. 다만, HDFS의 변경 사항이 반영되지 않는 문제를 보완하기 위해 Pod의 초기화 시점에 다음과 같이 매뉴얼한 동기화를 한 번 실행한다. 관련된 내용은 Alluxio CSI(3.3)를 참고하기 바란다.\n\n$ ./bin/alluxio fs ls -R -Dalluxio.user.file.metadata.sync.interval=0 /path/to/sync\n\n\n출처: https://docs.alluxio.io/os/user/stable/en/core-services/Unified-Namespace.html#periodic-metadata-sync\n\n사용 패턴에 따라서는 Pod이 초기화된 이후에도 항상 HDFS와 동기화가 필요할 수 있다. 이런 경우에는 alluxio.user.file.metadata.sync.interval=0를 설정할 수 있다. 다만, 네임노드 부담이 얼마나 가해지는지 모니터링해야 한다.\n\n도입 효과\n\nAiSuite에서는 Alluxio 도입으로 요구 사항을 모두 해결할 수 있었다.\n\n\n\n\n사용 편이성, 이식성: 일반적인 Kubernetes의 PersistentVolume 사용 방식에 따라 HDFS를 사용할 수 있다. 사용자는 HDFS 사용을 위한 러닝커브가 없으며, 기존의 소프트웨어에서도 별도의 개발없이 HDFS 사용이 가능하다.\n성능: 여러 IDC에 분산된 노드 사이의 IDC 간 트래픽을 줄이고 HDFS에 빠르게 접근할 수 있다.\nKubernetes 저장소로 HDFS 활용: AiSuite에서 생성한 AI 모델, 로그 등의 데이터를 안정적으로 보관하는 스토리지로서 HDFS를 사용할 수 있다.\n\n\n도입 시 고려 사항\n\nAlluxio 운영은 간단하지 않다. master, worker, CSI 등의 Alluxio 컴포넌트 관리뿐만 아니라, HDFS 네임노드로 얼마나 많은 요청이 가해지는지, 효과적인 캐싱 정책은 무엇인지 등의 다양한 고민이 생긴다.\n\n사용 방식 또는 환경에 따라서는 Alluxio가 도움이 되지 못할 수 있다. 이 경우 불필요한 운영 부담만 생길 수 있다.\n\nAlluxio 파일은 immutable하다\n\nHDFS 데이터를 읽기 위해 Alluxio를 사용하다면 대부분 잘 작동한다. 하지만 Alluxio를 통해 HDFS로 데이터를 쓰는 경우, Alluxio 파일은 immutable함을 이해하고 사용해야 한다. 즉, 이미 저장된 파일에 대한 변경(append, truncate)은 금지된다.\n\nbash-5.0$ cd /data/  \nbash-5.0$ echo \"appended\" >> myfile.txt  \nbash: echo: write error: File exists  \n\n\n이러한 제약으로 인해 기존에 잘 작동하던 코드가 Alluxio 마운트 경로를 지정하면 작동하지 않을 수도 있다.\n\nAiSuite에서는 작업 중 생성되는 임시 데이터는 Emphemeral Storage를 사용하고, 최종 결과를 영구적으로 HDFS에 저장하기 위해 Alluxio를 사용한다.\n\n캐싱 효과가 얼마나 있을까\n\nAlluxio 캐싱 효과를 위해서는 HDFS로부터 읽어들인 데이터가 여러 작업에서 사용되어야 한다. 항상 새로운 데이터를 사용하는 방식이라면 캐싱 효과를 얻기가 어렵다. \n또한 HDFS가 느린 저장매체에 저장되어 있거나 물리적으로 멀리 떨어진 경우에 효과적이다.\n\nAiSuite는 다중 테넌트 환경이므로 여러 사용자가 동일한 데이터를 활용하는 경우가 많다. 그뿐만 아니라, AiSuite의 노드들은 HDFS보다 빠른 저장매체를 가지면서 여러 IDC에 분산되어 있어 캐싱으로 인한 충분한 성능 향상을 기대할 수 있었다.\n\n마치며\n\n지금까지 Kubernetes 기반의 AI 플랫폼과 Apache Hadoop 기반의 데이터 플랫폼 간의 데이터 연결을 위해 Alluxio를 도입한 과정을 살펴보았다.\n\nAlluxio를 활용하면 다양한 인터페이스로 빠르게 HDFS에 접근할 수 있다. 하지만 AiSuite의 요구 사항에 따라 Alluxio CSI 개발, Locality 적용, HDFS 동기화 등의 검토가 필요했다.\n\nAiSuite에서의 Alluxio 도입은 HDFS에 빠르고 쉽게 접근하는 것이 목적이었다. 하지만 Alluxio는 HDFS뿐만 아니라 AWS S3, GCS, Ceph 등의 다양한 스토리지를 지원한다. 앞으로 AiSuite에서는 HDFS 외의 스토리지도 검토하려고 한다. 여기저기 흩어져 있는 AI 데이터를 통합하고 일관된 인터페이스로 접근하여 더 편리하게 AI 파이프라인을 구축하도록 지원할 계획이다.}","rawText":"고성능의 AI 모델을 개발하기 위해서는 좋은 알고리즘만큼이나 양질의 데이터가 중요합니다. 그렇기 때문에 대규모 데이터를 전처리하여 양질의 데이터로 만든 후 AI 플랫폼에서 이를 사용하는 것이 일반적입니다.\n\n네이버 검색에서는 어떻게 하고 있을까요? 네이버의 대규모 데이터는 데이터 저장소인 Cuve에 저장되어 있으며, Apache Hadoop 기반의 데이터 처리 플랫폼 C3에서 데이터를 처리합니다. 그리고 AI 학습 또는 서빙을 위해서는 Kubernetes 기반의 AI 플랫폼인 AiSuite를 사용합니다.\n\n즉, 네이버 검색에서 AI 서비스를 위한 데이터 흐름은 다음과 같습니다(AI&Data Platform 참고).\n\n\n데이터 저장 플랫폼 Cuve에서 대규모의 원본 데이터 관리  \n데이터 처리 플랫폼 C3에서 데이터 저장 플랫폼 Cuve의 데이터를 가공하여 HDFS에 저장  \nAiSuite는 데이터 처리 플랫폼 C3의 HDFS에 저장된 데이터를 사용\n\n\n결국 원활한 AI 파이프라인 개발을 위해서는 AiSuite에서 데이터 처리 플랫폼 C3의 HDFS에 빠르고 쉽게 접근할 수 있어야 합니다.\n\n\n\n본 문서에서는 Kubernetes 기반의 AI 플랫폼인 AiSuite에서 HDFS에 쉽고 빠르게 접근하기 위해 고민했던 내용을 공유합니다.\n\n요구 사항\n\n사용 편이성\n\nKubernetes에서 HDFS에 접근하기 위해서는 어떻게 해야 할까?\n\n단순하게 생각해보면 HDFS를 사용하는 방법은 어렵지 않다. Apache Hadoop 패키지, 클러스터 설정 파일을 배포하고 Kerberos 인증을 제공한 후 HDFS CLI, REST, Java API를 사용하여 접근할 수 있다.\n\n하지만 이는 Kubernetes에서 HDFS에 접근하려는 모든 컨테이너에 Apache Hadoop 패키지, 설정, 인증이 필요하다는 의미이다. 사용자가 매번 HDFS에 접근이 가능한 이미지를 직접 빌드하고 인증 방법을 마련해야 한다면 굉장히 번거로울 것이다. 그뿐만 아니라, HDFS CLI, REST, Java API 등을 이용한 HDFS 접근을 위한 코드 작성도 필요하다.\n\n따라서 HDFS를 사용하더라도 추가적인 개발이 없도록 지원해야 한다.\n\n이식성\n\nAiSuite는 Kubernetes 기반에서 Kubeflow, Knative, KServe 등의 다양한 소프트웨어를 활용하여 MLOps 환경을 제공한다.\n\n이렇게 다양한 소프트웨어에서 스토리지가 필요하다면 어떻게 지원할까? Kubernetes에서는 PersistentVolume을 마운트하여 사용하는 것이 일반적인 스토리지 사용 방법이다. HDFS를 스토리지로 사용하는 경우에도 이러한 방식을 지원한다면 Kubernetes에서 실행되는 어떠한 소프트웨어에서도 자연스럽게 HDFS를 사용할 수 있다.\n\n성능\n\nAiSuite의 GPU 노드는 여러 IDC에 걸쳐 분산되어 있으며, HDFS가 구축된 IDC와 다를 수 있다. 이러한 환경에서 항상 HDFS에 접근하는 경우 다량의 IDC 간 트래픽이 수시로 발생하며 데이터 전송이 지연된다.\n\nGPU를 활용하는 AI 작업에서 데이터 전송 지연은 단순히 오래 걸리는 것 이상의 비용이 발생한다. 일반적으로 GPU가 할당된 후 학습 또는 서빙에 필요한 데이터를 원격의 저장소로부터 가져오기 때문에, 데이터 전송이 지연된다면 그만큼 고비용의 GPU 자원을 낭비하는 것과 같다.\n\n따라서 한 번 읽은 데이터는 캐싱하여 효율적으로 접근하는 방법이 필요하다.\n\nKubernetes 저장소로 HDFS 활용\n\n클라우드 환경에서는 AWS S3, GCS와 같은 스토리지 서비스를 사용하여 안정적인 데이터 보관이 가능하다. 하지만 on-premise Kubernetes에서 영구적인 데이터 저장 스토리지는 어떻게 마련할 수 있을까?\n\n간단한 방법으로 nfs, local, hostpath 등을 생각할 수 있으나 고가용성 부족, 스케줄링 제한, 보안 취약 등의 문제가 있다. 안정적인 지원을 위해서는 Ceph, gluster 등의 분산 스토리지를 직접 구축하고 운영해야 하는 부담이 생긴다.\n\n이미 네이버에서는 데이터 처리 플랫폼 C3에서 지원하는 HDFS를 데이터 저장 용도로 사용하고 있다. 따라서 AiSuite에서 생성한 데이터를 HDFS에 저장한다면 별도의 분산 스토리지 도입 없이 안정적인 데이터 보관이 가능하다.\n\nAlluxio\n\nAlluxio란\n\n이러한 요구 사항을 위해 Alluxio를 검토했다.\n\nAlluxio는 Data Orchestration layer로 소개되며 다음과 같은 이점이 있다.\n\n\n물리적으로 멀리 떨어져 있거나 느린 저장매체에 저장된 데이터를 캐싱\nHDFS, AWS S3, GCS, Ceph 등의 다양한 스토리지에 원하는 인터페이스로 접근\n\n\nAlluxio는 주로 여러 클라우드 또는 내부 저장소의 데이터에 쉽고 빠르게 접근하기 위해 활용되고 있다.\n\n\nAWS S3에 저장된 데이터를 Spark, Presto 등에서 빠르게 처리\non-premise HDFS 데이터를 AWS, GCP 등의 클라우드에서 빠르게 접근\nAWS S3, GCS, Azure 등 여러 클라우드에 저장된 데이터 접근 방식을 일원화\n\n\n\n\nAlluxio의 아키텍처\n\nAlluxio는 파일의 메타 데이터를 관리하는 master와 데이터 블럭을 저장하는 다수의 worker로 구성되며, 이러한 구조는 HDFS와 유사하다. 하지만 데이터를 안정적으로 보관하는 용도라기보다는 캐싱과 다양한 인터페이스를 지원하여 데이터를 빠르고 쉽게 사용하는 데 목적이 있다.\n\n\n\n출처: https://docs.alluxio.io/os/user/stable/en/overview/Architecture.html\n\n데이터를 처음으로 읽는 경우에는 원본 저장소로부터 데이터를 가져오지만 이후에는 로컬 또는 다른 worker에 캐싱된 데이터를 가져오는 것이 기본적인 동작이다.\n\n\nlocal cache hit: 동일 노드의 worker에 캐싱된 데이터를 읽음(로컬 파일 시스템 속도)\nremote cache hit: 다른 노드의 worker에 캐싱된 데이터를 읽음(private network 속도)\ncache miss: 캐싱되어 있지 않은 경우 원본 저장소에서 데이터를 읽고 캐싱(원본 저장소 속도)\n\n\n\n\n출처: https://docs.alluxio.io/os/user/stable/en/overview/Architecture.html\n\n데이터를 쓰는 경우에도 용도에 따라 다양한 방식을 지원한다.\n\n\nMUST_CACHE: 임시 캐싱만 수행. 빠르지만 데이터 유실 가능\nCACHE_THROUGH: 원본 저장소로 저장한 이후 종료. 느리지만 안전한 데이터 보관\nASYNC_THROUGH: 캐싱 후 종료. 이후 비동기적으로 원본 저장소에 저장. 빠르지만 데이터 유실 가능\n\n\n\n\n출처: https://docs.alluxio.io/os/user/stable/en/overview/Architecture.html\n\n본 문서에서는 Alluxio 설치, 튜닝 방법 등의 상세한 내용을 다루지는 않는다. 자세한 내용은 alluxio.io을 참고하시기 바란다. 이후로는 AiSuite에 Alluxio를 도입하기 위해 고려했던 내용을 위주로 설명한다.\n\nKubernetes 저장소로 HDFS 활용\n\nAlluxio FUSE\n\nAlluxio는 데이터 접근을 위한 다양한 인터페이스를 지원하며, Linux FUSE 기반의 Alluxio FUSE를 사용하여 POSIX API를 지원한다. 즉, 별도의 Alluxio 라이브러리가 필요하지 않고 일반적인 파일 시스템과 동일하게 사용할 수 있다. 예를 들어, HDFS 접근 시에도 ls, mkdir, cat 등을 그대로 사용할 수 있으며, 데이터를 읽어오는 기존에 작성된 코드를 변경없이 사용할 수 있다. 이는 위의 요구 사항 중 사용 편이성, 이식성을 위해 필요하다.\n\n\n\n출처: https://docs.alluxio.io/os/user/edge/en/api/POSIX-API.html#choose-posix-api-implementation\n\n그렇다면 Alluxio FUSE를 Kubernetes에서 어떻게 지원해야 할까? 쉽게 떠오르는 것은 Kubernetes 모든 노드의 특정 경로에 Alluxio FUSE를 마운트하고 hostPath로 사용하는 것이다.\n\n하지만 AiSuite와 같이 여러 사용자가 함께 사용하는 다중 테넌트(multi-tenant) 환경에서는 다음과 같은 문제가 있다.\n\n\n하나의 FUSE 마운팅 포인트를 여러 사용자가 공유함으로서 성능 영향\n사용자별 HDFS 권한에 따른 접근 제어가 어려움\n\n\n그뿐만 아니라, hostPath는 보안 이슈를 일으킬 수 있어 부득이한 경우를 제외하면 사용하지 않도록 권고하고 있다. Kubernetes에서 스토리지는 PersistentVolume으로 사용하는 것이 일반적인 방식이다. Alluxio 파일 시스템에 접근하는 경우에도 이러한 방식을 지원하는 것이 필요하다.\n\n컨테이너 스토리지 인터페이스\n\nKubernetes에서 PersistentVolume은 어떻게 지원할 수 있을까?\n\n컨테이너 스토리지 인터페이스(이하 CSI)는 컨테이너 오케스트레이션 시스템(Kubernetes, swarm, mesos 등)에서 다양한 스토리지를 지원하기 위한 인터페이스를 정의한다. 이전에는 스토리지 지원을 위한 플러그인들이 컨테이너 오케스트레이션 시스템에 종속적이었다. 예를 들어, 스토리지 플러그인을 추가하거나 업데이트하려면 Kubernetes와 같이 컴파일 또는 배포되어야 했다. 하지만 CSI가 소개되면서 플러그인을 독립적으로 배포하고 관리할 수 있게 되었다. 즉, 스토리지 벤더측에서 CSI를 준수하는 스토리지 플러그인을 제공한다면 Kubernetes에 이를 배포하는 것으로 스토리지를 사용할 수 있다.\n\n\n\n출처: https://kubernetes.io/blog/2018/08/02/dynamically-expand-volume-with-csi-and-kubernetes/\n\nCSI에 대한 자세한 내용은 CSI spec을 참고하기 바란다.\n\nAlluxio CSI\n\n따라서 Alluxio 파일 시스템에 대한 CSI 스토리지 플러그인을 개발해야 한다는 걸 알 수 있다.\n\nAiSuite를 위한 플러그인은 아래와 같이 동작하도록 구현했다. 아래는 구현된 부분을 강조한 대략적인 흐름이다.\n\n\n\n(1) 사용자는 PVC(PersistentVolumeClaim), Pod 요청. 원하는 HDFS 경로를 PVC의 hdfs/namespace, hdfs/path로 명시\n\n(2.1) csi-provisioner에 의해 CreateVolume이 플러그인으로 요청\n\n(2.2) 플러그인은 PVC에 설정된 HDFS 경로를 Alluxio 파일 시스템과 마운트\n\n(3.1) Pod이 스케줄링되면, csi-attacher에 의해 ControllerPublishVolume이 플러그인으로 요청\n\n(3.2) 플러그인은 사용자가 PVC에 설정된 HDFS 경로에 대한 권한이 있는지 Ranger에 요청하여 확인\n\n(3.3) 플러그인은 HDFS와 Alluxio 파일 시스템과의 메타데이터 동기화 요청\n\n(4.1) 스케줄링된 노드의 kubelet은 NodePublishVolume을 플러그인으로 요청\n\n(4.2) 플러그인은 Alluxio 파일 시스템을 Pod 하위 경로에 Alluxio FUSE를 마운트하여 제공\n\nAlluxio에서도 Alluxio/alluxio-csi를 지원하지만, 다중 테넌트 환경에서 HDFS와 연동하기 위한 목적인 AiSuite에서는 다음과 같은 개발이 추가로 필요했다.\n\n\n사용자가 필요한 HDFS 경로를 직접 PVC에 설정하여 요청(1)\n여러 사용자가 공유하는 Alluxio 파일 시스템의 효율적인 사용을 위해 필요한 HDFS 경로만 캐싱(2.2)\nHDFS 접근 권한을 관리하는 Ranger와 연동하여 사용자 접근 제한(3.2)\nHDFS 네임노드로의 부하를 줄이기 위해 Pod 사용 시점에 한 번만 매뉴얼한 동기화 요청(3.3)(Alluxio와 HDFS 간 동기화 참고)\n\n\n결국 Alluxio CSI를 개발하여 HDFS를 일반적인 Kubernetes 스토리지와 동일한 방식으로 사용할 수 있게 되었다.\n\nAlluxio의 읽기 성능\n\nAlluxio 캐싱으로 인한 효과를 살펴보기 위해 여러 가지 조건에서 6.4GB 파일을 읽어 보았다. 테스트는 Alluxio 2.4.1에서 short-circuit read와 같은 성능 최적화 없이 진행되었다. 측정된 시간은 IDC 위치, 저장매체, Alluxio 버전 또는 설정 등에 영향을 받기 때문에 절대적인 것은 아니다.\n\n위에서 살펴본 대로 우리는 Alluxio FUSE가 필요하므로, Alluxio FUSE를 사용한 테스트를 진행했다.\n\n\n\n\nAlluxio FUSE로 캐싱되지 않은 파일을 읽는 경우(3), HDFS Client를 사용해 읽는 것(2)보다도 15% 가량 느려졌다. FUSE는 여러번 kernel-user 간 컨텍스트 스위칭이 발생하는데 이에 대한 오버헤드이다.\nAlluxio FUSE로 동일 노드에 캐싱된 파일을 읽는 경우(4), 캐싱되지 않는 파일을 읽는 경우(3)에 비해 5배 빠르게 읽어온다(short-circuit read 설정으로 더 빠른 속도도 기대할 수 있다).\nAlluxio FUSE로 다른 노드에 캐싱된 파일을 읽는 경우(5)에도 동일 노드에 캐싱된 파일을 읽는 경우(4)에 근사한 시간이 소요되었다.\n\n\nAlluxio 측에서도 Fuse 성능 개선에 노력하고 있으며, Alluxio 2.5.0부터는 성능을 개선한 JNI-Fuse를 사용할 수 있다.\n\n파일을 쓰는 경우에 대한 성능은 평가하지 않았다. AiSuite에서 Alluxio 파일을 쓰는 것은 HDFS를 안정적인 스토리지로 사용하기 위함이며, 따라서 HDFS로의 저장을 보장하는 CACHETHROUGH 방식을 사용한다. 따라서, 일반적인 HDFS Client를 사용하는 것과 비슷한 시간이 소요된다. 만약 데이터 유실을 감수할 수 있는 임시 데이터 보관이 목적이라면 MUSTCACHE를 사용하여 빠른 쓰기 성능을 기대할 수 있다.\n\nLocality\n\nAiSuite에 포함된 노드는 여러 IDC에 걸쳐 분산되어 있다. 데이터에 접근할 때 가능하면 IDC를 벗어나지 않고 근거리에서 데이터를 가져올 수 있어야 한다. 다른 IDC의 노드에서 데이터를 가져오는 경우, 느릴 뿐만 아니라 IDC 간 네트워크 트래픽 비용이 발생한다.\n\nAlluxio에서는 client, master, worker에 대해 locality를 부여하는 방법을 제공한다. Alluxio 파일 시스템에 접근하려는 client의 locality에 따라 어떤 worker로부터 캐싱된 데이터를 가져올지 결정할 수 있다.\n\nAiSuite에서는 node, zone, idc 순서로 locality를 고려하여 캐싱 데이터에 접근하도록 설정한다. zone은 용도에 따른 노드들의 그룹으로, 물리적으로 가까이 위치한다. 각 노드에는 node, zone, idc에 대한 Kubernetes node-label을 설정해두고, client, master, worker가 구동될 때 다음과 같은 alluxio.locality 설정이 반영되도록 했다.\n\n\nalluxio.locality.order=node,zone,idc\nalluxio.locality.node={노드의 호스트명}\nalluxio.locality.zone={노드가 소속된 zone명}\nalluxio.locality.idc={노드가 위치한 idc명}\n\n\n다음은 node=node1, zone=web, idc=seoul인 client에서 캐싱 데이터에 접근하는 예이다.\n\n\n\n\n같은 노드 node1에 캐싱된 데이터  \n같은 zone인 web에 캐싱된 데이터  \n같은 idc인 seoul에 캐싱된 데이터  \n그 외 다른 idc에 캐싱된 데이터\n\n\n만약 IDC 간 전송이 너무 느리거나 많은 비용이 발생한다면 어떻게 해야 할까? 다른 IDC에 캐싱된 데이터를 가져오는 것(위의 4번)보다, 같은 IDC의 HDFS에서 데이터를 가져오는 게 유리할 수 있다. 이 경우 alluxio.locality.idc.strict=true를 설정할 수 있다. 다른 IDC로의 요청 대신 HDFS로부터 데이터를 가져온다.\n\nAlluxio와 HDFS 간 동기화\n\nAlluxio는 HDFS 메타데이터(파일, 디렉터리 등의 정보)를 캐싱하여 빠르고 효율적으로 데이터를 사용하게 한다. 그뿐만 아니라, 메타데이터를 캐싱하여 HDFS 네임노드로의 불필요한 요청을 줄이는 이점도 있다.\n\n하지만 캐싱은 원본 저장소와의 불일치를 유발하기도 한다. Alluxio를 이용하여 파일, 디렉터리를 생성하는 경우에는 Alluxio 파일 시스템에 반영된다. 하지만 외부로부터 가해지는 HDFS 변경을 알 수는 없다. 예를 들어, Alluxio에서 /data/20220401을 캐싱하고 있는데 만약 Hive를 이용해 HDFS에 /data/20220402가 생성된다면 Alluxio는 알 수 없다.\n\n\n\n출처: https://www.alluxio.io/blog/two-ways-to-keep-files-in-sync-between-alluxio-and-hdfs\n\n이를 위해 Alluxio에서는 얼마나 자주 HDFS와 메타데이터 동기화를 해야 하는지 client 측에 설정할 수 있다.\n\n\nalluxio.user.file.metadata.sync.interval=-1는 한 번 캐싱한 이후로는 동기화하지 않는다. HDFS 네임노드로의 부담은 줄어들지만 동기화 문제가 발생할 수 있다.\nalluxio.user.file.metadata.sync.interval=0은 파일 접근이 있을 때마다 HDFS 메타데이터를 동기화한다. 동기화 문제는 없지만, HDFS 네임노드로 항상 listStatus 요청이 발생하여 네임노드에 부담을 준다.\nalluxio.user.file.metadata.sync.interval=1m는 1분마다 HDFS 메타데이터와 동기화한다. 1분마다 주기적으로 listStatus 요청이 발생한다.\n\n\n우리가 사용하는 C3S HDFS는 수많은 사용자가 있다. 따라서 무엇보다도 네임노드 부담을 줄이기 위한 방안이 필요하므로 alluxio.user.file.metadata.sync.interval=-1를 기본으로 사용한다. 다만, HDFS의 변경 사항이 반영되지 않는 문제를 보완하기 위해 Pod의 초기화 시점에 다음과 같이 매뉴얼한 동기화를 한 번 실행한다. 관련된 내용은 Alluxio CSI(3.3)를 참고하기 바란다.\n\n$ ./bin/alluxio fs ls -R -Dalluxio.user.file.metadata.sync.interval=0 /path/to/sync\n\n\n출처: https://docs.alluxio.io/os/user/stable/en/core-services/Unified-Namespace.html#periodic-metadata-sync\n\n사용 패턴에 따라서는 Pod이 초기화된 이후에도 항상 HDFS와 동기화가 필요할 수 있다. 이런 경우에는 alluxio.user.file.metadata.sync.interval=0를 설정할 수 있다. 다만, 네임노드 부담이 얼마나 가해지는지 모니터링해야 한다.\n\n도입 효과\n\nAiSuite에서는 Alluxio 도입으로 요구 사항을 모두 해결할 수 있었다.\n\n\n\n\n사용 편이성, 이식성: 일반적인 Kubernetes의 PersistentVolume 사용 방식에 따라 HDFS를 사용할 수 있다. 사용자는 HDFS 사용을 위한 러닝커브가 없으며, 기존의 소프트웨어에서도 별도의 개발없이 HDFS 사용이 가능하다.\n성능: 여러 IDC에 분산된 노드 사이의 IDC 간 트래픽을 줄이고 HDFS에 빠르게 접근할 수 있다.\nKubernetes 저장소로 HDFS 활용: AiSuite에서 생성한 AI 모델, 로그 등의 데이터를 안정적으로 보관하는 스토리지로서 HDFS를 사용할 수 있다.\n\n\n도입 시 고려 사항\n\nAlluxio 운영은 간단하지 않다. master, worker, CSI 등의 Alluxio 컴포넌트 관리뿐만 아니라, HDFS 네임노드로 얼마나 많은 요청이 가해지는지, 효과적인 캐싱 정책은 무엇인지 등의 다양한 고민이 생긴다.\n\n사용 방식 또는 환경에 따라서는 Alluxio가 도움이 되지 못할 수 있다. 이 경우 불필요한 운영 부담만 생길 수 있다.\n\nAlluxio 파일은 immutable하다\n\nHDFS 데이터를 읽기 위해 Alluxio를 사용하다면 대부분 잘 작동한다. 하지만 Alluxio를 통해 HDFS로 데이터를 쓰는 경우, Alluxio 파일은 immutable함을 이해하고 사용해야 한다. 즉, 이미 저장된 파일에 대한 변경(append, truncate)은 금지된다.\n\nbash-5.0$ cd /data/  \nbash-5.0$ echo \"appended\" >> myfile.txt  \nbash: echo: write error: File exists  \n\n\n이러한 제약으로 인해 기존에 잘 작동하던 코드가 Alluxio 마운트 경로를 지정하면 작동하지 않을 수도 있다.\n\nAiSuite에서는 작업 중 생성되는 임시 데이터는 Emphemeral Storage를 사용하고, 최종 결과를 영구적으로 HDFS에 저장하기 위해 Alluxio를 사용한다.\n\n캐싱 효과가 얼마나 있을까\n\nAlluxio 캐싱 효과를 위해서는 HDFS로부터 읽어들인 데이터가 여러 작업에서 사용되어야 한다. 항상 새로운 데이터를 사용하는 방식이라면 캐싱 효과를 얻기가 어렵다. \n또한 HDFS가 느린 저장매체에 저장되어 있거나 물리적으로 멀리 떨어진 경우에 효과적이다.\n\nAiSuite는 다중 테넌트 환경이므로 여러 사용자가 동일한 데이터를 활용하는 경우가 많다. 그뿐만 아니라, AiSuite의 노드들은 HDFS보다 빠른 저장매체를 가지면서 여러 IDC에 분산되어 있어 캐싱으로 인한 충분한 성능 향상을 기대할 수 있었다.\n\n마치며\n\n지금까지 Kubernetes 기반의 AI 플랫폼과 Apache Hadoop 기반의 데이터 플랫폼 간의 데이터 연결을 위해 Alluxio를 도입한 과정을 살펴보았다.\n\nAlluxio를 활용하면 다양한 인터페이스로 빠르게 HDFS에 접근할 수 있다. 하지만 AiSuite의 요구 사항에 따라 Alluxio CSI 개발, Locality 적용, HDFS 동기화 등의 검토가 필요했다.\n\nAiSuite에서의 Alluxio 도입은 HDFS에 빠르고 쉽게 접근하는 것이 목적이었다. 하지만 Alluxio는 HDFS뿐만 아니라 AWS S3, GCS, Ceph 등의 다양한 스토리지를 지원한다. 앞으로 AiSuite에서는 HDFS 외의 스토리지도 검토하려고 한다. 여기저기 흩어져 있는 AI 데이터를 통합하고 일관된 인터페이스로 접근하여 더 편리하게 AI 파이프라인을 구축하도록 지원할 계획이다.}","href":"https://d2.naver.com/d2.atomAI 플랫폼과 데이터 플랫폼을 이어주는 Alluxio 적용기"}