{"company":{"imageUrl":"/companyImages/naver.ico","name":"네이버","href":"https://d2.naver.com/d2.atom","basePath":"https://d2.naver.com","rssUrl":"https://d2.naver.com/d2.atom"},"title":"네이버 검색 SRE 1편 - 차세대 검색 모니터링 시스템을 향한 여정","createdAt":"2023-01-20T12:22:26Z","description":"<ul>\n<li><a href=\"#ch1\">개발 배경</a>\n<ul><li><a href=\"#ch1_1\">네이버 검색 SRE의 목표</a></li>\n<li><a href=\"#ch1_2\">네이버 검색 규모와 SRE 도입 배경</a></li>\n<li><a href=\"#ch1_3\">기존 네이버 검색 모니터링 시스템과 한계</a></li></ul></li>\n<li><a href=\"#ch2\">차세대 검색 모니터링 시스템 개발 과정</a>\n<ul><li><a href=\"#ch2_1\">차세대 모니터링 시스템의 목표</a></li>\n<li><a href=\"#ch2_2\">차세대 모니터링 시스템 설계</a></li>\n<li><a href=\"#ch2_3\">차세대 모니터링 시스템 개발시 마주했던 문제점과 해결</a></li>\n<li><a href=\"#ch2_4\">차세대 모니터링 시스템의 개선 효과</a></li></ul></li>\n<li><a href=\"#ch3\">마무리</a></li>\n</ul>\n\n<p>2016년 9월 12일, 네이버는 경주 지진으로 약 10분간 검색 서비스를 제공하지 못하는 중대한 장애를 경험한 적이 있습니다. 경주 지진으로 인한 장애 이후 네이버 검색 시스템의 신뢰성 보장을 위해 SRE(Site Reliability Engineering)라는 방법론을 도입하기 시작했습니다. 그리고 현재 2023년까지 약 6년이라는 긴 시간 동안 안정적인 검색 서비스를 제공하기 위해 노력을 계속 이어 나가고 있습니다. 그 결과 검색 SRE가 지원하는 검색 서비스는 장애율 1% 이하의 지표를 유지하고 있습니다.</p>\n\n<p>이번 시리즈는 지난 포스팅 이후부터 2022년까지의 검색 SRE 활동을 총 두 편으로 준비했습니다. 이전의 저희 이야기가 궁금하시다면, <a href=\"https://d2.naver.com/helloworld/2047663\">D2 Hello World: 네이버 검색의 SRE 시스템</a>에서 소개한 검색 SRE 시스템을 참고해 주세요.</p>\n\n<ul>\n<li>1편: 차세대 검색 모니터링 시스템을 향한 여정</li>\n<li>2편: 측정하지 않으면 개선할 수 없다! SRE KPI 개발기</li>\n</ul>\n\n<p>1편에서 다룰 내용은 차세대 검색 모니터링 시스템 개발 과정입니다. 지난 몇 년간 운영해온 기존의 네이버 검색 시스템 모니터링에서 새로운 검색 모니터링 시스템으로 전환하며 어떻게 검색 안정성을 높여나갈 수 있었는지 소개해 드리도록 하겠습니다.</p>\n\n<p><a id=\"ch1\"></a></p>\n\n<h2 id=\"\">개발 배경</h2>\n\n<p><a id=\"ch1_1\"></a></p>\n\n<h3 id=\"sre\">네이버 검색 SRE의 목표</h3>\n\n<p>네이버의 검색 서비스는 사용자의 요구에 맞추어 끊임없이 성장하며 진화하고 있다. 성장과 진화 과정에서 변경은 필연적으로 동반되는데, 이런 변경은 검색 서비스의 안정성에 영향을 주기도 한다.</p>\n\n<p>변경에 따른 크고 작은 장애는 어느 곳에나 있다. 하지만 사용자는 이와 상관없이 검색 서비스가 의도한 대로 잘 동작하기를 바란다. 사용자의 기대에 부응하며 안정적인 검색 시스템을 제공하기 위해 검색 SRE가 추구하는 두 가지 목표는 다음과 같다.</p>\n\n<ul>\n<li>지표 이상 현상을 감지했을 때 빠르게 파악하고 초기 상황을 전파할 수 있어야 한다.</li>\n<li>장애에 의한 영향도를 빠르고 정확하게 확인할 수 있어야 한다.</li>\n</ul>\n\n<p>위 두 가지 목표를 달성하기 위해, 기존의 네이버 검색 모니터링 시스템을 어떻게 개선했는지 그 과정을 소개하겠다.</p>\n\n<p><a id=\"ch1_2\"></a></p>\n\n<h3 id=\"sre\">네이버 검색 규모와 SRE 도입 배경</h3>\n\n<p>2023년 1월을 기준으로, 네이버 검색은 수만 대 규모의 서버를 기반으로 수백 개의 서비스로 구성되어 있다. 네이버 검색이 성장함에 따라 검색을 구성하는 서비스 간의 관계도 점점 복잡해지고 있는데, 이에 따라 어느 한 서비스의 장애가 주변 시스템의 장애로 번지는 일이 일어나기도 한다.</p>\n\n<p><img src=\"/content/images/2023/01/920f60d5-c811-495a-84b8-5e9e8713a021.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 1 복잡하게 그물망처럼 얽힌 네이버 검색 서비스 일부분에 장애가 발생한다면?</span></p>\n\n<p>기존의 네이버 검색 모니터링 시스템은 이러한 배경으로 탄생했다. 수많은 서비스 간 의존도와 복잡도가 높아진 상황에서, 전체 검색 서비스를 관제하는 SRE 주도 장애 관제의 필요성이 대두되었다. 장애를 신속하게 파악하고 정확하게 문제 원인을 공유하기 위해서는 모두가 함께 보는 시스템이 필요했다.</p>\n\n<p><a id=\"ch1_3\"></a></p>\n\n<h3 id=\"\">기존 네이버 검색 모니터링 시스템과 한계</h3>\n\n<blockquote>\n  <p>네이버 검색에서 사용되던 기존 모니터링 시스템은 <a href=\"https://d2.naver.com/helloworld/2047663\">D2 Hello World: 네이버 검색의 SRE 시스템</a>에서 소개한 바 있다.</p>\n</blockquote>\n\n<p>장애 발생 시 상황 파악을 위해 기존 개발했던 모니터링 시스템은 지난 몇 년간 별다른 문제가 없는 것처럼 보였다.\n그러나 점차 기존 시스템을 운영하며 발견한 구조적 문제점이 수면 위로 드러나기 시작했다.</p>\n\n<h4 id=\"1\">한계 1. 지표 확인 및 알람 딜레이</h4>\n\n<p>아래 그림의 데이터 파이프라인을 살펴보면 데이터 수집, 저장, 알람이 Crontab 기반 1분 단위 배치 구조로 수행되다 보니 시스템 대기 시간 때문에 필연적으로 2~3분의 시스템 딜레이가 발생하는 구조적 한계가 있었다.</p>\n\n<p><img src=\"/content/images/2023/01/2ba6fdc4-60df-4615-9e21-698868320496.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 2 배치 구조로 대기 딜레이가 발생하는 기존 시스템</span></p>\n\n<p>언뜻 보면 전체 데이터를 처리하고 확인하는 데까지 2~3분이면 네이버 검색 규모에 비해 그렇게 오래 걸리는 것은 아니라고 생각할 수 있다. 그러나 기존 모니터링 시스템을 이용하여 실시간으로 대응하는 온콜 멤버가 느끼는 2~3분 가량의 딜레이는 실제 시간보다 훨씬 답답하게 느껴지기 마련이다.</p>\n\n<p>예를 하나 들어 보면, 2022년 10월 29일 토요일 오전 8시 27분 충북 괴산 지진이 발생했을 때, 재난 문자를 수신한 직후 담당 온콜이 모니터링 시스템에 접속했는데 시스템 딜레이 때문에 실시간 트래픽이 아닌 2~3분 전 트래픽을 확인할 수밖에 없는 상황이라면 매우 난감할 것이다.</p>\n\n<p><img src=\"/content/images/2023/01/1e66348f-b4de-4008-83a7-a38961a6ae3e.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 3 시스템 딜레이가 실시간 비상 대응에 미치는 영향</span></p>\n\n<h4 id=\"2\">한계 2. 시스템 딜레이에 따른 의사 결정 지연</h4>\n\n<p>이상 징후 탐지에 소요되는 시스템 딜레이는 모니터링 시스템에 매우 치명적인 영향을 미친다. 시스템 딜레이에 따라 의사 결정 시간 또한 지연되기 때문이다. 이는 마치 사고 직전에 있는 자동차가 눈을 감은 상태로 3분 동안 핸들을 조향하지 못하는 것과 다름이 없다. 그뿐만 아니라 추후 자동화 대응 시스템을 연동하더라도 동작을 기대하는 시간보다 시스템 딜레이만큼 늦게 동작하게 될 것이다.</p>\n\n<p><img src=\"/content/images/2023/01/d5fd2a5b-fc92-4400-8aa1-31611f7b0bd0.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 4 장애 지속 시간에 영향일 미치는 이상 징후 탐지 딜레이</span></p>\n\n<h4 id=\"3\">한계 3. 필요한 데이터 확인의 어려움</h4>\n\n<p>배치 구조 때문에 발생하는 시스템 딜레이를 개선하는 이슈와 별개로, 사람이 데이터를 확인하는 데 걸리는 시간을 줄이는 것 또한 매우 중요한 문제이다.</p>\n\n<p>예를 들자면 아래 기존 모니터링 시스템의 UI 데이터 테이블은 정보가 너무 많기 때문에 사용자가 장애 상황 파악에 필요한 데이터를 식별하기 어려웠다. 긴급한 순간 30초란 시간이 주어진다면, 아래와 같은 화면에서 장애 분석에 필요한 정보를 올바르게 획득할 수 있을까?</p>\n\n<p><img src=\"/content/images/2023/01/54376fee-3405-45bc-9fdb-e2309e6597c2.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 5 원하는 정보를 확인할 수 없을 만큼 복잡해져버린 기존 시스템의 데이터 테이블</span></p>\n\n<p><a id=\"ch2\"></a></p>\n\n<h2 id=\"\">차세대 검색 모니터링 시스템 개발 과정</h2>\n\n<p><a id=\"ch2_1\"></a></p>\n\n<h3 id=\"\">차세대 모니터링 시스템의 목표</h3>\n\n<p>기존 모니터링 시스템을 차세대 모니터링 시스템으로 전환하며 삼았던 목표는 크게 3가지이다.</p>\n\n<ul>\n<li><strong>초스피드</strong>: 기존 최대 180초 소요되었던 지표 확인과 알람 딜레이를 60초 이내로 단축하여 이상 현상을 빠르게 감지할 것</li>\n<li><strong>고해상도</strong>: 기존 서비스 해상도를 마이크로 서비스 해상도로 확대할 것</li>\n<li><strong>데이터 가독성 향상</strong>: 기존 데이터 테이블의 정보 과다 노출을 줄이고 반드시 의사 결정에 필요한 데이터만 노출할 것</li>\n</ul>\n\n<p>위 3가지 목표를 모두 달성하기 위해 시스템을 밑바탕부터 다시 고민하고 설계하기 시작했다.</p>\n\n<p><a id=\"ch2_2\"></a></p>\n\n<h3 id=\"\">차세대 모니터링 시스템 설계</h3>\n\n<p>기존 모니터링 시스템의 가장 큰 문제점은 '수집 - 처리 - 저장 - 알람' 배치가 하나의 프로젝트로 구성되어 불필요한 대기 시간이 발생했다는 점이다. 이런 구조적 문제 때문에 모든 배치가 순차적으로 진행되다 보니, 이전 작업이 모두 끝나지 않으면 다음 작업을 진행할 수 없었다. 불필요한 대기 시간으로 인해 지표 확인과 알람 발송에 총 2~3분 가량 딜레이가 발생하는 암울한 결과를 낳았다. 그리고 기하급수적으로 늘어가는 서버 수와 서비스 개수에 비례하여 지난 몇 년간 지표 확인 및 알람 발송 딜레이는 해가 갈수록 늘어나는 상황이 지속되었다.</p>\n\n<p><img src=\"/content/images/2023/01/f62152f0-ae53-4e49-9c20-7ce9e5686768.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 6 기존 시스템 대기 딜레이가 발생하는 구간 확인</span></p>\n\n<p>위에서 말했던 3가지 차세대 모니터링 시스템 목표 (대기 딜레이 단축, 해상도 확대, 데이터 가시성)를 달성하기 위해 팀 내에서 리팩토링이 아닌 시스템을 처음부터 다시 설계한다는 중대한 결정을 내리게 되었다. 수집, 처리, 저장, 알람을 담당하는 컴포넌트의 역할과 책임을 분리했으며 대기 딜레이 단축을 위해 기존 배치 구조에서 스트림 구조로 변경하기 위한 노력을 기울였다.</p>\n\n<p>기존 시스템 운영 경험과 교훈을 바탕으로 새로운 시스템을 설계할 때 기대했던 점은 아래와 같다.</p>\n\n<ul>\n<li><strong>짧은 대기 시간</strong>: 낭비되는 대기 시간을 최대한 줄일 것</li>\n<li><strong>리플레이와 시뮬레이션</strong>: 수집, 처리, 저장, 알람은 언제든지 리플레이 가능하도록 할 것, 그리고 시뮬레이션될 수 있도록 할 것</li>\n<li><strong>단일 컴포넌트 책임 축소</strong>: 컴포넌트 간 역할과 관계를 분리하고, 단일 컴포넌트가 너무 큰 책임을 지지 않도록 할 것</li>\n</ul>\n\n<p>이런 기대치를 달성하기 위하여 가장 크게 구조를 변경했던 부분은 단일 배치 스크립트의 분리였다. 앞에서 언급했던 것처럼 단일 배치 스크립트가 전부 담당했던 '수집 - 처리 - 저장 - 알람' 단계를 새로운 여러 컴포넌트로 위임하여 분리하였고 이를 도식화하면 아래와 같다.</p>\n\n<p><img src=\"/content/images/2023/01/3d52c647-971d-4f08-a9b6-a6f7fcfeab09.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 7 차세대 검색 모니터링 시스템 딜레이와 설계 모식도</span></p>\n\n<p><a id=\"ch2_3\"></a></p>\n\n<h3 id=\"\">차세대 모니터링 시스템 개발 시 마주쳤던 난관과 해결 방법</h3>\n\n<p>설계 과정에서 계획했던 것처럼 이상적으로 흘러갔으면 좋았겠지만, 현실의 개발 과정은 희망과 목표처럼 순탄치만 않았다. 기존 검색 모니터링 시스템을 운영하는 동시에 완전히 패러다임이 다른 차세대 시스템을 개발하는 과정에서 마주쳤던 난관과 해결 방법을 소개하겠다.</p>\n\n<p>첫 번째 문제는 알람 기준 시각에 따른 데이터 신뢰성 문제이다. 데이터 흐름을 시간에 따라 나타내면 아래와 같다. 순차적인 수집, 처리 및 저장, 알람 순서로 이루어져 있다.</p>\n\n<p><img src=\"/content/images/2023/01/6ef70bac-6ffc-429e-8995-f969f6a7e8c2.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 8 기존 시스템의 순차적 배치 처리</span></p>\n\n<p>이 흐름을 스트림으로 변경하면 아래와 같이 데이터 수집과 처리가 모두 완료되지 않은 상태에서 알람을 평가하기도 한다. 그런데 이렇게 되면 데이터를 신뢰할 수 없는 순간에 읽고 평가될 수 있으므로 잘못된 경보가 발생할 가능성이 높아진다. 데이터 수집과 처리가 끝나지 않은 순간 알람이 평가된다면 어떤 일이 벌어질까? 알람 주기마다 잘못된 경보가 발생할 것이다. 아마 Grafana를 사용하는 분은 새로 고침을 계속 클릭하다 보면 아래 그림과 같이 데이터가 쌓이기 전 조회되는 현상과 마주친 적이 분명 있을 것이다.</p>\n\n<p><img src=\"/content/images/2023/01/c56d353a-d428-454f-8717-6c832e67d6ec.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 9 차세대 시스템의 스트림 혼합 배치 처리</span></p>\n\n<p>이런 문제를 해결하기 위해 각 처리 단계의 완료 시간을 측정해, 통계를 기반으로 데이터 신뢰가 가능한 시각을 30초로 설정했다. 그리고 데이터 신뢰 가능 시각까지 기다린 후 알람을 평가하도록 변경하여, 신뢰할 수 있는 알람이 발생하도록 처리했다.</p>\n\n<p><img src=\"/content/images/2023/01/9b51a12e-76a5-4f85-bb75-6857f9117c84.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 10 데이터 신뢰 가능한 시각 설정, 이후 알람 스트림 처리</span></p>\n\n<p>두 번째 문제는, 기존에 배치 스크립트에 녹여냈던 휴릭스틱을 Time Series Database (TSDB) 질의 언어와 관제 규칙으로 모두 위임한다는 초기 설계 철학의 한계를 발견한 것이었다.</p>\n\n<p>기존 배치 코드에 스파게티 형식으로 담았던 휴리스틱 알고리즘을 코드가 아닌 외부로 최대한 분리하려 했지만 생각보다 아름답게 정리되지는 않았다. 많은 시행착오 끝에 결국 이상과 현실 사이에서 어느 정도 타협을 할 수밖에 없다는 것을 알게 되었고, 대신 보이 스카우트 규칙(캠프장은 처음 왔을 때보다 더 깨끗하게 해놓고 떠나라)만큼은 꼭 지키기로 했다.</p>\n\n<p>처음에 기대했던 대로 100% 완벽하게 코드를 정리하지는 못했지만 약 70% 정도의 지저분한 로직은 설정, 데이터베이스, 템플릿, 질의로 분리해내어 기존 구조보다는 훨씬 유지보수가 수월해졌다.</p>\n\n<p><img src=\"/content/images/2023/01/9455ec69-1e7a-4cbc-a022-2deef3daf132.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 11 휴리스틱 알고리즘을 위임하여 코드라인 수 70% 감소</span></p>\n\n<p>마지막 문제는, '언제 시스템을 전환하는 것이 좋을지' 결정하는 것이었다. 기존 시스템을 운영하면서 새로운 시스템으로 전환을 결정하려면 시스템 전환 기준이 반드시 필요하다.</p>\n\n<p>시스템 개발을 80% 가까이 진행해 보니, 새로운 구현과 정책에 따라서 100% 완벽하게 기존 시스템을 이식하는 것은 불가능하다는 판단을 내렸다. 기존 시스템 대비 90% 정확도 수준의 시뮬레이션 결과를 도출하면 <strong>기존 시스템과 알람 발생에 통계적으로 큰 차이가 없다</strong>는 실험 결과에 따라 90%의 알람 정확도와 지표 정확도를 기준으로 삼았다.</p>\n\n<p><img src=\"/content/images/2023/01/c4e55098-713c-427b-abac-bd6165c50008-2.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 12 기존 시스템과 신규 서비스를 시뮬레이션하여 동일한 알람이 발생하는지 확인</span></p>\n\n<p><img src=\"/content/images/2023/01/fb5c9dc3-ebe3-414e-a641-b42316c55d16.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 13 기존 시스템과 신규 서비스는 어떤 서비스 지표가 차이 나는지 나타내는 데이터 테이블</span></p>\n\n<p>위와 같이 개발과 전환에서 만났던 문제를 차근차근 해결해 나가다 보니 결과물이 보이기 시작했다.</p>\n\n<p><a id=\"ch2_4\"></a></p>\n\n<h3 id=\"\">차세대 모니터링 시스템의 개선 효과</h3>\n\n<p>차세대 시스템이 90%의 정확도 수준에 도달한 이후, 기존 시스템과 차세대 시스템의 상호 전환을 완료했다.</p>\n\n<p>초기 설계부터, 실제 구현에서 마주한 문제를 해결해 나가며 결국 목표로 했던 초스피드, 고해상도, 데이터 가독성의 3가지 시스템 개선 목표를 모두 달성했다.</p>\n\n<p><img src=\"/content/images/2023/01/a96897ea-7f10-4065-8a39-e23c09570f21.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 14 기존 시스템과 신규 서비스의 성능 차이</span></p>\n\n<ul>\n<li>초스피드: 기존 최대 180초가 소요되었던 지표 확인과 알람 딜레이를 60초 이내로 단축하여 이상 현상을 보다 빠르게 감지<br />\n기존 시스템에선 배치 처리 때문에 앞 단계의 데이터 처리를 모두 기다려야 해서 2분 이상 시스템 대기로 낭비되는 시간이 있었지만, 새로운 시스템은 이런 불필요한 대기 시간을 스트림 병렬 처리로 줄여 데이터 확인 및 알람 시간을 2분 이상 앞당겼다.</li>\n</ul>\n\n<p><img src=\"/content/images/2023/01/85033d7e-d395-4ee9-b51e-18554abc3670.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 15 기존 시스템과 신규 서비스의 차트 UI 변경점</span></p>\n\n<ul>\n<li>고해상도: 기존 차트의 서비스 해상도를 마이크로 서비스 해상도 단위로 확대<br />\n기존 시스템은 하나의 서비스 데이터를 Aggregation 처리했다. 이에 따라서 해상도가 낮아져 필요한 마이크로 서비스 데이터를 확인할 수 없는 문제가 있었다. 개선된 시스템에선 데이터를 Aggregation 처리하는 대신 Raw data를 모두 저장하도록 하여 서비스뿐만 아니라 마이크로 서비스의 데이터까지 확인할 수 있었다. 즉, ETL (Extract, Transform, Load) 처리를 ELT (Extract, Load, Transform)로 변경했다고 볼 수 있다. 추가로 차트 UI에 알람 기준을 배경으로 가시화하여 현재 위험도 수준이 어떤지 더욱 명확히 볼 수 있도록 했다.</li>\n</ul>\n\n<p><img src=\"/content/images/2023/01/536f5b75-2b29-4009-9b9a-0cc1280622a1.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 16 기존 시스템과 신규 서비스의 데이터 테이블 UI 변경점</span></p>\n\n<ul>\n<li>데이터 가독성 향상: 기존 데이터 테이블의 정보 과다 노출을 해결하고, 차트와 테이블에서 반드시 의사 결정에 필요한 데이터만 한정하여 노출<br />\n기존 시스템 UI는 너무 많은 정보가 노출되어 어떤 정보를 봐야 할지 알 수 없었다. 시스템을 개선하며 테이블 형식의 UI를 카드 형태의 UI로 간략화하여 어떤 서비스의 레이어에 이상이 있는지 한눈에 확인할 수 있었다.</li>\n</ul>\n\n<p>이렇게 목표로 했던 초스피드, 고해상도, 데이터 가독성 3가지 목표를 모두 달성하여, 검색 시스템의 문제 발생 시 장애 지속 시간에 큰 영향을 미치는 이상 징후 탐지 시간을 기존 최대 3분에서 1분 이내로 단축할 수 있었다. 이에 따라 중대한 장애 발생 시 신속하게 의사 결정을 내릴 수 있었고, 장애 지속 시간을 단축시킬 수 있었다.</p>\n\n<p><img src=\"/content/images/2023/01/a993e05b-113a-4017-a52f-c4be353b2ecf.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 17 이상 현상 파악 딜레이 단축으로 인한 장애 지속 시간 감소</span></p>\n\n<p><a id=\"ch3\"></a></p>\n\n<h2 id=\"\">마무리</h2>\n\n<p>우리 네이버 검색 SRE는 이렇게 많은 우여곡절을 겪어왔고 또 앞으로도 계속 겪을 예정이다. 우리가 직접 개발한 모니터링 시스템을 수년간 운영하면서 겪은 각종 시행착오를 바탕으로 차세대 시스템이 만들어진 만큼 더욱 단단하고 강력해졌을 것이라고 믿고 있다. 또 이렇게 차근차근 지속적인 개선을 해나간다면 앞으로도 전 국민이 사용하는 네이버 검색 서비스를 계속 든든하게 뒷받침할 수 있을 것이라 기대한다.</p>\n\n<p>이어지는 다음 편에서는 검색 SRE 조직의 KPI 개발 과정을 소개하겠다.</p>","rawText":"<ul>\n<li><a href=\"#ch1\">개발 배경</a>\n<ul><li><a href=\"#ch1_1\">네이버 검색 SRE의 목표</a></li>\n<li><a href=\"#ch1_2\">네이버 검색 규모와 SRE 도입 배경</a></li>\n<li><a href=\"#ch1_3\">기존 네이버 검색 모니터링 시스템과 한계</a></li></ul></li>\n<li><a href=\"#ch2\">차세대 검색 모니터링 시스템 개발 과정</a>\n<ul><li><a href=\"#ch2_1\">차세대 모니터링 시스템의 목표</a></li>\n<li><a href=\"#ch2_2\">차세대 모니터링 시스템 설계</a></li>\n<li><a href=\"#ch2_3\">차세대 모니터링 시스템 개발시 마주했던 문제점과 해결</a></li>\n<li><a href=\"#ch2_4\">차세대 모니터링 시스템의 개선 효과</a></li></ul></li>\n<li><a href=\"#ch3\">마무리</a></li>\n</ul>\n\n<p>2016년 9월 12일, 네이버는 경주 지진으로 약 10분간 검색 서비스를 제공하지 못하는 중대한 장애를 경험한 적이 있습니다. 경주 지진으로 인한 장애 이후 네이버 검색 시스템의 신뢰성 보장을 위해 SRE(Site Reliability Engineering)라는 방법론을 도입하기 시작했습니다. 그리고 현재 2023년까지 약 6년이라는 긴 시간 동안 안정적인 검색 서비스를 제공하기 위해 노력을 계속 이어 나가고 있습니다. 그 결과 검색 SRE가 지원하는 검색 서비스는 장애율 1% 이하의 지표를 유지하고 있습니다.</p>\n\n<p>이번 시리즈는 지난 포스팅 이후부터 2022년까지의 검색 SRE 활동을 총 두 편으로 준비했습니다. 이전의 저희 이야기가 궁금하시다면, <a href=\"https://d2.naver.com/helloworld/2047663\">D2 Hello World: 네이버 검색의 SRE 시스템</a>에서 소개한 검색 SRE 시스템을 참고해 주세요.</p>\n\n<ul>\n<li>1편: 차세대 검색 모니터링 시스템을 향한 여정</li>\n<li>2편: 측정하지 않으면 개선할 수 없다! SRE KPI 개발기</li>\n</ul>\n\n<p>1편에서 다룰 내용은 차세대 검색 모니터링 시스템 개발 과정입니다. 지난 몇 년간 운영해온 기존의 네이버 검색 시스템 모니터링에서 새로운 검색 모니터링 시스템으로 전환하며 어떻게 검색 안정성을 높여나갈 수 있었는지 소개해 드리도록 하겠습니다.</p>\n\n<p><a id=\"ch1\"></a></p>\n\n<h2 id=\"\">개발 배경</h2>\n\n<p><a id=\"ch1_1\"></a></p>\n\n<h3 id=\"sre\">네이버 검색 SRE의 목표</h3>\n\n<p>네이버의 검색 서비스는 사용자의 요구에 맞추어 끊임없이 성장하며 진화하고 있다. 성장과 진화 과정에서 변경은 필연적으로 동반되는데, 이런 변경은 검색 서비스의 안정성에 영향을 주기도 한다.</p>\n\n<p>변경에 따른 크고 작은 장애는 어느 곳에나 있다. 하지만 사용자는 이와 상관없이 검색 서비스가 의도한 대로 잘 동작하기를 바란다. 사용자의 기대에 부응하며 안정적인 검색 시스템을 제공하기 위해 검색 SRE가 추구하는 두 가지 목표는 다음과 같다.</p>\n\n<ul>\n<li>지표 이상 현상을 감지했을 때 빠르게 파악하고 초기 상황을 전파할 수 있어야 한다.</li>\n<li>장애에 의한 영향도를 빠르고 정확하게 확인할 수 있어야 한다.</li>\n</ul>\n\n<p>위 두 가지 목표를 달성하기 위해, 기존의 네이버 검색 모니터링 시스템을 어떻게 개선했는지 그 과정을 소개하겠다.</p>\n\n<p><a id=\"ch1_2\"></a></p>\n\n<h3 id=\"sre\">네이버 검색 규모와 SRE 도입 배경</h3>\n\n<p>2023년 1월을 기준으로, 네이버 검색은 수만 대 규모의 서버를 기반으로 수백 개의 서비스로 구성되어 있다. 네이버 검색이 성장함에 따라 검색을 구성하는 서비스 간의 관계도 점점 복잡해지고 있는데, 이에 따라 어느 한 서비스의 장애가 주변 시스템의 장애로 번지는 일이 일어나기도 한다.</p>\n\n<p><img src=\"/content/images/2023/01/920f60d5-c811-495a-84b8-5e9e8713a021.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 1 복잡하게 그물망처럼 얽힌 네이버 검색 서비스 일부분에 장애가 발생한다면?</span></p>\n\n<p>기존의 네이버 검색 모니터링 시스템은 이러한 배경으로 탄생했다. 수많은 서비스 간 의존도와 복잡도가 높아진 상황에서, 전체 검색 서비스를 관제하는 SRE 주도 장애 관제의 필요성이 대두되었다. 장애를 신속하게 파악하고 정확하게 문제 원인을 공유하기 위해서는 모두가 함께 보는 시스템이 필요했다.</p>\n\n<p><a id=\"ch1_3\"></a></p>\n\n<h3 id=\"\">기존 네이버 검색 모니터링 시스템과 한계</h3>\n\n<blockquote>\n  <p>네이버 검색에서 사용되던 기존 모니터링 시스템은 <a href=\"https://d2.naver.com/helloworld/2047663\">D2 Hello World: 네이버 검색의 SRE 시스템</a>에서 소개한 바 있다.</p>\n</blockquote>\n\n<p>장애 발생 시 상황 파악을 위해 기존 개발했던 모니터링 시스템은 지난 몇 년간 별다른 문제가 없는 것처럼 보였다.\n그러나 점차 기존 시스템을 운영하며 발견한 구조적 문제점이 수면 위로 드러나기 시작했다.</p>\n\n<h4 id=\"1\">한계 1. 지표 확인 및 알람 딜레이</h4>\n\n<p>아래 그림의 데이터 파이프라인을 살펴보면 데이터 수집, 저장, 알람이 Crontab 기반 1분 단위 배치 구조로 수행되다 보니 시스템 대기 시간 때문에 필연적으로 2~3분의 시스템 딜레이가 발생하는 구조적 한계가 있었다.</p>\n\n<p><img src=\"/content/images/2023/01/2ba6fdc4-60df-4615-9e21-698868320496.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 2 배치 구조로 대기 딜레이가 발생하는 기존 시스템</span></p>\n\n<p>언뜻 보면 전체 데이터를 처리하고 확인하는 데까지 2~3분이면 네이버 검색 규모에 비해 그렇게 오래 걸리는 것은 아니라고 생각할 수 있다. 그러나 기존 모니터링 시스템을 이용하여 실시간으로 대응하는 온콜 멤버가 느끼는 2~3분 가량의 딜레이는 실제 시간보다 훨씬 답답하게 느껴지기 마련이다.</p>\n\n<p>예를 하나 들어 보면, 2022년 10월 29일 토요일 오전 8시 27분 충북 괴산 지진이 발생했을 때, 재난 문자를 수신한 직후 담당 온콜이 모니터링 시스템에 접속했는데 시스템 딜레이 때문에 실시간 트래픽이 아닌 2~3분 전 트래픽을 확인할 수밖에 없는 상황이라면 매우 난감할 것이다.</p>\n\n<p><img src=\"/content/images/2023/01/1e66348f-b4de-4008-83a7-a38961a6ae3e.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 3 시스템 딜레이가 실시간 비상 대응에 미치는 영향</span></p>\n\n<h4 id=\"2\">한계 2. 시스템 딜레이에 따른 의사 결정 지연</h4>\n\n<p>이상 징후 탐지에 소요되는 시스템 딜레이는 모니터링 시스템에 매우 치명적인 영향을 미친다. 시스템 딜레이에 따라 의사 결정 시간 또한 지연되기 때문이다. 이는 마치 사고 직전에 있는 자동차가 눈을 감은 상태로 3분 동안 핸들을 조향하지 못하는 것과 다름이 없다. 그뿐만 아니라 추후 자동화 대응 시스템을 연동하더라도 동작을 기대하는 시간보다 시스템 딜레이만큼 늦게 동작하게 될 것이다.</p>\n\n<p><img src=\"/content/images/2023/01/d5fd2a5b-fc92-4400-8aa1-31611f7b0bd0.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 4 장애 지속 시간에 영향일 미치는 이상 징후 탐지 딜레이</span></p>\n\n<h4 id=\"3\">한계 3. 필요한 데이터 확인의 어려움</h4>\n\n<p>배치 구조 때문에 발생하는 시스템 딜레이를 개선하는 이슈와 별개로, 사람이 데이터를 확인하는 데 걸리는 시간을 줄이는 것 또한 매우 중요한 문제이다.</p>\n\n<p>예를 들자면 아래 기존 모니터링 시스템의 UI 데이터 테이블은 정보가 너무 많기 때문에 사용자가 장애 상황 파악에 필요한 데이터를 식별하기 어려웠다. 긴급한 순간 30초란 시간이 주어진다면, 아래와 같은 화면에서 장애 분석에 필요한 정보를 올바르게 획득할 수 있을까?</p>\n\n<p><img src=\"/content/images/2023/01/54376fee-3405-45bc-9fdb-e2309e6597c2.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 5 원하는 정보를 확인할 수 없을 만큼 복잡해져버린 기존 시스템의 데이터 테이블</span></p>\n\n<p><a id=\"ch2\"></a></p>\n\n<h2 id=\"\">차세대 검색 모니터링 시스템 개발 과정</h2>\n\n<p><a id=\"ch2_1\"></a></p>\n\n<h3 id=\"\">차세대 모니터링 시스템의 목표</h3>\n\n<p>기존 모니터링 시스템을 차세대 모니터링 시스템으로 전환하며 삼았던 목표는 크게 3가지이다.</p>\n\n<ul>\n<li><strong>초스피드</strong>: 기존 최대 180초 소요되었던 지표 확인과 알람 딜레이를 60초 이내로 단축하여 이상 현상을 빠르게 감지할 것</li>\n<li><strong>고해상도</strong>: 기존 서비스 해상도를 마이크로 서비스 해상도로 확대할 것</li>\n<li><strong>데이터 가독성 향상</strong>: 기존 데이터 테이블의 정보 과다 노출을 줄이고 반드시 의사 결정에 필요한 데이터만 노출할 것</li>\n</ul>\n\n<p>위 3가지 목표를 모두 달성하기 위해 시스템을 밑바탕부터 다시 고민하고 설계하기 시작했다.</p>\n\n<p><a id=\"ch2_2\"></a></p>\n\n<h3 id=\"\">차세대 모니터링 시스템 설계</h3>\n\n<p>기존 모니터링 시스템의 가장 큰 문제점은 '수집 - 처리 - 저장 - 알람' 배치가 하나의 프로젝트로 구성되어 불필요한 대기 시간이 발생했다는 점이다. 이런 구조적 문제 때문에 모든 배치가 순차적으로 진행되다 보니, 이전 작업이 모두 끝나지 않으면 다음 작업을 진행할 수 없었다. 불필요한 대기 시간으로 인해 지표 확인과 알람 발송에 총 2~3분 가량 딜레이가 발생하는 암울한 결과를 낳았다. 그리고 기하급수적으로 늘어가는 서버 수와 서비스 개수에 비례하여 지난 몇 년간 지표 확인 및 알람 발송 딜레이는 해가 갈수록 늘어나는 상황이 지속되었다.</p>\n\n<p><img src=\"/content/images/2023/01/f62152f0-ae53-4e49-9c20-7ce9e5686768.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 6 기존 시스템 대기 딜레이가 발생하는 구간 확인</span></p>\n\n<p>위에서 말했던 3가지 차세대 모니터링 시스템 목표 (대기 딜레이 단축, 해상도 확대, 데이터 가시성)를 달성하기 위해 팀 내에서 리팩토링이 아닌 시스템을 처음부터 다시 설계한다는 중대한 결정을 내리게 되었다. 수집, 처리, 저장, 알람을 담당하는 컴포넌트의 역할과 책임을 분리했으며 대기 딜레이 단축을 위해 기존 배치 구조에서 스트림 구조로 변경하기 위한 노력을 기울였다.</p>\n\n<p>기존 시스템 운영 경험과 교훈을 바탕으로 새로운 시스템을 설계할 때 기대했던 점은 아래와 같다.</p>\n\n<ul>\n<li><strong>짧은 대기 시간</strong>: 낭비되는 대기 시간을 최대한 줄일 것</li>\n<li><strong>리플레이와 시뮬레이션</strong>: 수집, 처리, 저장, 알람은 언제든지 리플레이 가능하도록 할 것, 그리고 시뮬레이션될 수 있도록 할 것</li>\n<li><strong>단일 컴포넌트 책임 축소</strong>: 컴포넌트 간 역할과 관계를 분리하고, 단일 컴포넌트가 너무 큰 책임을 지지 않도록 할 것</li>\n</ul>\n\n<p>이런 기대치를 달성하기 위하여 가장 크게 구조를 변경했던 부분은 단일 배치 스크립트의 분리였다. 앞에서 언급했던 것처럼 단일 배치 스크립트가 전부 담당했던 '수집 - 처리 - 저장 - 알람' 단계를 새로운 여러 컴포넌트로 위임하여 분리하였고 이를 도식화하면 아래와 같다.</p>\n\n<p><img src=\"/content/images/2023/01/3d52c647-971d-4f08-a9b6-a6f7fcfeab09.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 7 차세대 검색 모니터링 시스템 딜레이와 설계 모식도</span></p>\n\n<p><a id=\"ch2_3\"></a></p>\n\n<h3 id=\"\">차세대 모니터링 시스템 개발 시 마주쳤던 난관과 해결 방법</h3>\n\n<p>설계 과정에서 계획했던 것처럼 이상적으로 흘러갔으면 좋았겠지만, 현실의 개발 과정은 희망과 목표처럼 순탄치만 않았다. 기존 검색 모니터링 시스템을 운영하는 동시에 완전히 패러다임이 다른 차세대 시스템을 개발하는 과정에서 마주쳤던 난관과 해결 방법을 소개하겠다.</p>\n\n<p>첫 번째 문제는 알람 기준 시각에 따른 데이터 신뢰성 문제이다. 데이터 흐름을 시간에 따라 나타내면 아래와 같다. 순차적인 수집, 처리 및 저장, 알람 순서로 이루어져 있다.</p>\n\n<p><img src=\"/content/images/2023/01/6ef70bac-6ffc-429e-8995-f969f6a7e8c2.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 8 기존 시스템의 순차적 배치 처리</span></p>\n\n<p>이 흐름을 스트림으로 변경하면 아래와 같이 데이터 수집과 처리가 모두 완료되지 않은 상태에서 알람을 평가하기도 한다. 그런데 이렇게 되면 데이터를 신뢰할 수 없는 순간에 읽고 평가될 수 있으므로 잘못된 경보가 발생할 가능성이 높아진다. 데이터 수집과 처리가 끝나지 않은 순간 알람이 평가된다면 어떤 일이 벌어질까? 알람 주기마다 잘못된 경보가 발생할 것이다. 아마 Grafana를 사용하는 분은 새로 고침을 계속 클릭하다 보면 아래 그림과 같이 데이터가 쌓이기 전 조회되는 현상과 마주친 적이 분명 있을 것이다.</p>\n\n<p><img src=\"/content/images/2023/01/c56d353a-d428-454f-8717-6c832e67d6ec.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 9 차세대 시스템의 스트림 혼합 배치 처리</span></p>\n\n<p>이런 문제를 해결하기 위해 각 처리 단계의 완료 시간을 측정해, 통계를 기반으로 데이터 신뢰가 가능한 시각을 30초로 설정했다. 그리고 데이터 신뢰 가능 시각까지 기다린 후 알람을 평가하도록 변경하여, 신뢰할 수 있는 알람이 발생하도록 처리했다.</p>\n\n<p><img src=\"/content/images/2023/01/9b51a12e-76a5-4f85-bb75-6857f9117c84.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 10 데이터 신뢰 가능한 시각 설정, 이후 알람 스트림 처리</span></p>\n\n<p>두 번째 문제는, 기존에 배치 스크립트에 녹여냈던 휴릭스틱을 Time Series Database (TSDB) 질의 언어와 관제 규칙으로 모두 위임한다는 초기 설계 철학의 한계를 발견한 것이었다.</p>\n\n<p>기존 배치 코드에 스파게티 형식으로 담았던 휴리스틱 알고리즘을 코드가 아닌 외부로 최대한 분리하려 했지만 생각보다 아름답게 정리되지는 않았다. 많은 시행착오 끝에 결국 이상과 현실 사이에서 어느 정도 타협을 할 수밖에 없다는 것을 알게 되었고, 대신 보이 스카우트 규칙(캠프장은 처음 왔을 때보다 더 깨끗하게 해놓고 떠나라)만큼은 꼭 지키기로 했다.</p>\n\n<p>처음에 기대했던 대로 100% 완벽하게 코드를 정리하지는 못했지만 약 70% 정도의 지저분한 로직은 설정, 데이터베이스, 템플릿, 질의로 분리해내어 기존 구조보다는 훨씬 유지보수가 수월해졌다.</p>\n\n<p><img src=\"/content/images/2023/01/9455ec69-1e7a-4cbc-a022-2deef3daf132.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 11 휴리스틱 알고리즘을 위임하여 코드라인 수 70% 감소</span></p>\n\n<p>마지막 문제는, '언제 시스템을 전환하는 것이 좋을지' 결정하는 것이었다. 기존 시스템을 운영하면서 새로운 시스템으로 전환을 결정하려면 시스템 전환 기준이 반드시 필요하다.</p>\n\n<p>시스템 개발을 80% 가까이 진행해 보니, 새로운 구현과 정책에 따라서 100% 완벽하게 기존 시스템을 이식하는 것은 불가능하다는 판단을 내렸다. 기존 시스템 대비 90% 정확도 수준의 시뮬레이션 결과를 도출하면 <strong>기존 시스템과 알람 발생에 통계적으로 큰 차이가 없다</strong>는 실험 결과에 따라 90%의 알람 정확도와 지표 정확도를 기준으로 삼았다.</p>\n\n<p><img src=\"/content/images/2023/01/c4e55098-713c-427b-abac-bd6165c50008-2.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 12 기존 시스템과 신규 서비스를 시뮬레이션하여 동일한 알람이 발생하는지 확인</span></p>\n\n<p><img src=\"/content/images/2023/01/fb5c9dc3-ebe3-414e-a641-b42316c55d16.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 13 기존 시스템과 신규 서비스는 어떤 서비스 지표가 차이 나는지 나타내는 데이터 테이블</span></p>\n\n<p>위와 같이 개발과 전환에서 만났던 문제를 차근차근 해결해 나가다 보니 결과물이 보이기 시작했다.</p>\n\n<p><a id=\"ch2_4\"></a></p>\n\n<h3 id=\"\">차세대 모니터링 시스템의 개선 효과</h3>\n\n<p>차세대 시스템이 90%의 정확도 수준에 도달한 이후, 기존 시스템과 차세대 시스템의 상호 전환을 완료했다.</p>\n\n<p>초기 설계부터, 실제 구현에서 마주한 문제를 해결해 나가며 결국 목표로 했던 초스피드, 고해상도, 데이터 가독성의 3가지 시스템 개선 목표를 모두 달성했다.</p>\n\n<p><img src=\"/content/images/2023/01/a96897ea-7f10-4065-8a39-e23c09570f21.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 14 기존 시스템과 신규 서비스의 성능 차이</span></p>\n\n<ul>\n<li>초스피드: 기존 최대 180초가 소요되었던 지표 확인과 알람 딜레이를 60초 이내로 단축하여 이상 현상을 보다 빠르게 감지<br />\n기존 시스템에선 배치 처리 때문에 앞 단계의 데이터 처리를 모두 기다려야 해서 2분 이상 시스템 대기로 낭비되는 시간이 있었지만, 새로운 시스템은 이런 불필요한 대기 시간을 스트림 병렬 처리로 줄여 데이터 확인 및 알람 시간을 2분 이상 앞당겼다.</li>\n</ul>\n\n<p><img src=\"/content/images/2023/01/85033d7e-d395-4ee9-b51e-18554abc3670.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 15 기존 시스템과 신규 서비스의 차트 UI 변경점</span></p>\n\n<ul>\n<li>고해상도: 기존 차트의 서비스 해상도를 마이크로 서비스 해상도 단위로 확대<br />\n기존 시스템은 하나의 서비스 데이터를 Aggregation 처리했다. 이에 따라서 해상도가 낮아져 필요한 마이크로 서비스 데이터를 확인할 수 없는 문제가 있었다. 개선된 시스템에선 데이터를 Aggregation 처리하는 대신 Raw data를 모두 저장하도록 하여 서비스뿐만 아니라 마이크로 서비스의 데이터까지 확인할 수 있었다. 즉, ETL (Extract, Transform, Load) 처리를 ELT (Extract, Load, Transform)로 변경했다고 볼 수 있다. 추가로 차트 UI에 알람 기준을 배경으로 가시화하여 현재 위험도 수준이 어떤지 더욱 명확히 볼 수 있도록 했다.</li>\n</ul>\n\n<p><img src=\"/content/images/2023/01/536f5b75-2b29-4009-9b9a-0cc1280622a1.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 16 기존 시스템과 신규 서비스의 데이터 테이블 UI 변경점</span></p>\n\n<ul>\n<li>데이터 가독성 향상: 기존 데이터 테이블의 정보 과다 노출을 해결하고, 차트와 테이블에서 반드시 의사 결정에 필요한 데이터만 한정하여 노출<br />\n기존 시스템 UI는 너무 많은 정보가 노출되어 어떤 정보를 봐야 할지 알 수 없었다. 시스템을 개선하며 테이블 형식의 UI를 카드 형태의 UI로 간략화하여 어떤 서비스의 레이어에 이상이 있는지 한눈에 확인할 수 있었다.</li>\n</ul>\n\n<p>이렇게 목표로 했던 초스피드, 고해상도, 데이터 가독성 3가지 목표를 모두 달성하여, 검색 시스템의 문제 발생 시 장애 지속 시간에 큰 영향을 미치는 이상 징후 탐지 시간을 기존 최대 3분에서 1분 이내로 단축할 수 있었다. 이에 따라 중대한 장애 발생 시 신속하게 의사 결정을 내릴 수 있었고, 장애 지속 시간을 단축시킬 수 있었다.</p>\n\n<p><img src=\"/content/images/2023/01/a993e05b-113a-4017-a52f-c4be353b2ecf.png\" alt=\"image\" /></p>\n\n<p><span class=\"caption\">그림 17 이상 현상 파악 딜레이 단축으로 인한 장애 지속 시간 감소</span></p>\n\n<p><a id=\"ch3\"></a></p>\n\n<h2 id=\"\">마무리</h2>\n\n<p>우리 네이버 검색 SRE는 이렇게 많은 우여곡절을 겪어왔고 또 앞으로도 계속 겪을 예정이다. 우리가 직접 개발한 모니터링 시스템을 수년간 운영하면서 겪은 각종 시행착오를 바탕으로 차세대 시스템이 만들어진 만큼 더욱 단단하고 강력해졌을 것이라고 믿고 있다. 또 이렇게 차근차근 지속적인 개선을 해나간다면 앞으로도 전 국민이 사용하는 네이버 검색 서비스를 계속 든든하게 뒷받침할 수 있을 것이라 기대한다.</p>\n\n<p>이어지는 다음 편에서는 검색 SRE 조직의 KPI 개발 과정을 소개하겠다.</p>","href":"this.company.rssUrl네이버 검색 SRE 1편 - 차세대 검색 모니터링 시스템을 향한 여정"}